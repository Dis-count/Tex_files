\documentclass[UTF8]{article}

\usepackage{ctex}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{booktabs}  % 用于三线表宏包
\usepackage{multirow}  % 多行合并表格

\usepackage{geometry}
\geometry{a4paper,scale=0.8}
\usepackage{graphicx}
\usepackage{amssymb}

% \documentclass[journal]{IEEEtran}
\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{epsfig}

\usepackage{setspace}
\renewcommand{\baselinestretch}{1.5}

\renewcommand{\algorithmicrequire}{\textbf{Input:}} % Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm

\begin{document}

\section{Style 1.}

\begin{algorithm}[htb]

\caption{Framework of ensemble learning for our system.}
\label{alg:Framwork}
\begin{algorithmic}[1]
\Require
The set of positive samples for current batch, $P_n$;
The set of unlabelled samples for current batch, $U_n$;
Ensemble of classifiers on former batches, $E_{n-1}$;
\Ensure
Ensemble of classifiers on the current batch, $E_n$;
\State Extracting the set of reliable negative and/or positive samples $T_n$ from $U_n$ with help of $P_n$;
\label{code:fram:extract}
\State Training ensemble of classifiers $E$ on $T_n \cup P_n$, with help of data in former batches;
\label{code:fram:trainbase}
\State $E_n=E_{n-1}cup E$;
\label{code:fram:add}
\State Classifying samples in $U_n-T_n$ by $E_n$;
\label{code:fram:classify}
\State Deleting some weak classifiers in $E_n$ so as to keep the capacity of $E_n$;
\label{code:fram:select} \\
\Return $E_n$;
\end{algorithmic}
\end{algorithm}


\section{Style 2.}

\begin{algorithm}[h]
\caption{An example for format For \& While Loop in Algorithm}
\begin{algorithmic}[1]
\For{each $i\in [1,9]$}
\State initialize a tree $T_{i}$ with only a leaf (the root);
\State $T=T\cup T_{i};$
\EndFor
\ForAll {$c$ such that $c\in RecentMBatch(E_{n-1})$}
\label{code:TrainBase:getc}
\State $T=T\cup PosSample(c)$;
\label{code:TrainBase:pos}
\EndFor;
\For{$i=1$; $i<n$; $i++$ }
\State $//$ Your source here;
\EndFor
\For{$i=1$ to $n$}
\State $//$ Your source here;
\EndFor
\State $//$ Reusing recent base classifiers.
\label{code:recentStart}
\While {$(|E_n| \leq L_1 )and( D \neq \phi)$}
\State Selecting the most recent classifier $c_i$ from $D$;
\State $D=D-c_i$;
\State $E_n=E_n+c_i$;
\EndWhile
\label{code:recentEnd}
\end{algorithmic}
\end{algorithm}

\section{Style 3.}

\begin{algorithm}[h]
\caption{Conjugate Gradient Algorithm with Dynamic Step-Size Control}
\label{alg::conjugateGradient}
\begin{algorithmic}[1]
\Require
$f(x)$: objective funtion;
$x_0$: initial solution;
$s$: step size;
\Ensure
optimal $x^{*}$
\State initial $g_0=0$ and $d_0=0$;
\Repeat
\State compute gradient directions $g_k=\bigtriangledown f(x_k)$;
\State compute Polak-Ribiere parameter $\beta_k=\frac{g_k^{T}(g_k-g_{k-1})}{\parallel g_{k-1} \parallel^{2}}$;
\State compute the conjugate directions $d_k=-g_k+\beta_k d_{k-1}$;
\State compute the step size $\alpha_k=s/\parallel d_k \parallel_{2}$;
\Until{($f(x_k)>f(x_{k-1})$)}
\end{algorithmic}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
\section{Style 4.}
\usepackage[linesnumbered,boxed]{algorithm2e}

\begin{algorithm}
\caption{identifyRowContext}
\KwIn{$r_i$, $Backgrd(T_i)$=${T_1,T_2,\ldots ,T_n}$ and similarity threshold $\theta_r$}
\KwOut{$con(r_i)$}
$con(r_i)= \Phi$\;
\For{$j=1;j \le n;j \ne i$}
{
float $maxSim=0$\;
$r^{maxSim}=null$\;
\While{not end of $T_j$}
{
compute Jaro($r_i,r_m$)($r_m\in T_j$)\;
\If{$(Jaro(r_i,r_m) \ge \theta_r)\wedge (Jaro(r_i,r_m)\ge r^{maxSim})$}
{
replace $r^{maxSim}$ with $r_m$\;
}
}
$con(r_i)=con(r_i)\cup {r^{maxSim}}$\;
}
return $con(r_i)$\;
\end{algorithm}

如果想要去掉算法中的竖线:

在\begin{algorithm}之后加入\SetAlgoNoLine

\fi

\begin{algorithm}[h]
\caption{Test}
\begin{algorithmic}[1]

\begin{description}
  \item[Step 1.]
  \item[Step 2.]
\end{description}

\end{algorithmic}
\end{algorithm}



\end{document}
